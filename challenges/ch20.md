# Chapter 20 Challenges

I skipped the implementation for this chapter. Rust gives me `HashSet`, `HashMap` and string value equality out of the box, so functionally I'm on par.

I don't find interning strings by default very compelling as an idea, at least not in the way it's implemented in `clox`. Here we have a language with no effects except to print to stdout, so strings can only have their origins in source. This makes it reasonably likely to be acceptable, but does not guarantee it, and the moment this language actually becomes usable, it's my position that string interning would have to go and quickly.

So basically, it seems we're just adding it for the sake of introducing the concept and getting comfortable with the basics. I'll pass.

## Challenge 1

> In clox, we happen to only need keys that are strings, so the hash table we built is hardcoded for that key type. If we exposed hash tables to Lox users as a first-class collection, it would be useful to support different kinds of keys.
>
> Add support for keys of the other primitive types: numbers, Booleans, and nil. Later, clox will support user-defined classes. If we want to support keys that are instances of those classes, what kind of complexity does that add?

No point implementing this as I have this for free too, for everything except doubles. This is for a good reason, as double value equality is not actually that useful a thing to have available and can be very misleading. demonstrating that

It forces us to choose between value or reference hashing, or (ideally) pass some measure of control over this to the user, including implementation of the former.

This is a hard problem that few mainstream languages handle well:

-   Javascript does reference equality for everything to do with objects (including functions)... except strings. It gets stranger. Key equality doesn't follow the exact same rules as `===` equality checks. It
-   Java does almost everything with non-primitives by reference by default which is at least pretty consistent, if not actually useful.
-   C# is a wild ride. It _looks_ Java-like, but forbids non-explicit reference equality, permits operator overloading _and_ has an `IEquatable` interface as two independent ideas. It's much better than Java... in too many ways. It's not clear to everyone exactly what should be used when, leaving room for weirdness.has a few differences. They make it better, but still different. Really weird.
-   Rust and Haskell are (as usual) great examples, because everything is explicit, and a lot is made available for free. `Eq` and `Hash` are implemented for basically all primitives that make sense (including pointers, for when reference equality is wanted), and you can derive or implement them youself based on them. If you do those things, you get to play in the `HashSet`/`HashMap` sandpits. If you don't,

## Challenge 2

> Hash tables have a lot of knobs you can tweak that affect their performance. You decide whether to use separate chaining or open addressing. Depending on which fork in that road you take, you can tune how many entries are stored in each node, or the probing strategy you use. You control the hash function, load factor, and growth rate.
>
> All of this variety wasn’t created just to give CS doctoral candidates something to publish theses on: each has its uses in the many varied domains and hardware scenarios where hashing comes into play. Look up a few hash table implementations in different open source systems, research the choices they made, and try to figure out why they did things that way.

Ew no. This sounds very boring, and I'm happy to take library authors' words that I'm getting sane defaults, or to start looking at stuff like [this](https://github.com/google/hashtable-benchmarks) if I'm ever dealing with enough data that I'm actually worried.

## Challenge 3

> Benchmarking a hash table is notoriously difficult. A hash table implementation may perform well with some keysets and poorly with others. It may work well at small sizes but degrade as it grows, or vice versa. It may choke when deletions are common, but fly when they aren’t. Creating benchmarks that accurately represent how your users will use the hash table is a challenge.
>
> Write a handful of different benchmark programs to validate our hash table implementation. How does the performance vary between them? Why did you choose the specific test cases you chose?

I'd automate a search for source files on github and benchmark them with different algorithms/parameters.

Anything less than "how people use it" is basically worthless. Real life hashtable people talk about this:
https://groups.google.com/g/hashtable-benchmarks/c/2-cbY4cJfIc
